{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5sakO_14o3Y",
        "outputId": "b869a19d-ade2-4696-ffa8-a03df47faf3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Handwriting-Prediction-and-Synthesis-master\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/Handwriting-Prediction-and-Synthesis-master'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8S0CU2P2fz0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install svgwrite"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpneGA9v453Z",
        "outputId": "34ccc2b0-660a-47e5-ed12-8bc7f1803a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting svgwrite\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: svgwrite\n",
            "Successfully installed svgwrite-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import numpy as np\n",
        "import svgwrite\n",
        "from IPython.display import SVG, display\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "use_cuda = False\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from ipywidgets import FloatProgress\n",
        "\n",
        "n_batch = 20\n",
        "sequence_length = 400\n",
        "U_items = int(sequence_length/25)\n",
        "\n",
        "hidden_size = 256\n",
        "n_layers = 3\n",
        "n_gaussians = 20\n",
        "Kmixtures = 10\n",
        "\n",
        "eps = float(np.finfo(np.float32).eps)\n",
        "\n",
        "# Hyperparameters\n",
        "gradient_threshold = 10\n",
        "dropout = 0.2\n",
        "\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "QnekTxCR4ppj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bounds(data, factor):\n",
        "    min_x = 0\n",
        "    max_x = 0\n",
        "    min_y = 0\n",
        "    max_y = 0\n",
        "\n",
        "    abs_x = 0\n",
        "    abs_y = 0\n",
        "    for i in range(len(data)):\n",
        "        x = float(data[i, 0]) / factor\n",
        "        y = float(data[i, 1]) / factor\n",
        "        abs_x += x\n",
        "        abs_y += y\n",
        "        min_x = min(min_x, abs_x)\n",
        "        min_y = min(min_y, abs_y)\n",
        "        max_x = max(max_x, abs_x)\n",
        "        max_y = max(max_y, abs_y)\n",
        "\n",
        "    return (min_x, max_x, min_y, max_y)\n",
        "\n",
        "# old version, where each path is entire stroke (smaller svg size, but\n",
        "# have to keep same color)\n",
        "\n",
        "\n",
        "def draw_strokes(data, factor=10, svg_filename='sample.svg'):\n",
        "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
        "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
        "\n",
        "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
        "    dwg.add(dwg.rect(insert=(0, 0), size=dims, fill='white'))\n",
        "\n",
        "    lift_pen = 1\n",
        "\n",
        "    abs_x = 25 - min_x\n",
        "    abs_y = 25 - min_y\n",
        "    p = \"M%s,%s \" % (abs_x, abs_y)\n",
        "\n",
        "    command = \"m\"\n",
        "\n",
        "    for i in range(len(data)):\n",
        "        if (lift_pen == 1):\n",
        "            command = \"m\"\n",
        "        elif (command != \"l\"):\n",
        "            command = \"l\"\n",
        "        else:\n",
        "            command = \"\"\n",
        "        x = float(data[i, 0]) / factor\n",
        "        y = float(data[i, 1]) / factor\n",
        "        lift_pen = data[i, 2]\n",
        "        p += command + str(x) + \",\" + str(y) + \" \"\n",
        "\n",
        "    the_color = \"black\"\n",
        "    stroke_width = 1\n",
        "\n",
        "    dwg.add(dwg.path(p).stroke(the_color, stroke_width).fill(\"none\"))\n",
        "\n",
        "    dwg.save()\n",
        "    display(SVG(dwg.tostring()))\n",
        "\n",
        "\n",
        "def draw_strokes_eos_weighted(\n",
        "        stroke,\n",
        "        param,\n",
        "        factor=10,\n",
        "        svg_filename='sample_eos.svg'):\n",
        "    c_data_eos = np.zeros((len(stroke), 3))\n",
        "    for i in range(len(param)):\n",
        "        # make color gray scale, darker = more likely to eos\n",
        "        c_data_eos[i, :] = (1 - param[i][6][0]) * 225\n",
        "    draw_strokes_custom_color(\n",
        "        stroke,\n",
        "        factor=factor,\n",
        "        svg_filename=svg_filename,\n",
        "        color_data=c_data_eos,\n",
        "        stroke_width=3)\n",
        "\n",
        "\n",
        "def draw_strokes_random_color(\n",
        "        stroke,\n",
        "        factor=10,\n",
        "        svg_filename='sample_random_color.svg',\n",
        "        per_stroke_mode=True):\n",
        "    c_data = np.array(np.random.rand(len(stroke), 3) * 240, dtype=np.uint8)\n",
        "    if per_stroke_mode:\n",
        "        switch_color = False\n",
        "        for i in range(len(stroke)):\n",
        "            if switch_color == False and i > 0:\n",
        "                c_data[i] = c_data[i - 1]\n",
        "            if stroke[i, 2] < 1:  # same strike\n",
        "                switch_color = False\n",
        "            else:\n",
        "                switch_color = True\n",
        "    draw_strokes_custom_color(\n",
        "        stroke,\n",
        "        factor=factor,\n",
        "        svg_filename=svg_filename,\n",
        "        color_data=c_data,\n",
        "        stroke_width=2)\n",
        "\n",
        "\n",
        "def draw_strokes_custom_color(\n",
        "        data,\n",
        "        factor=10,\n",
        "        svg_filename='test.svg',\n",
        "        color_data=None,\n",
        "        stroke_width=1):\n",
        "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
        "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
        "\n",
        "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
        "    dwg.add(dwg.rect(insert=(0, 0), size=dims, fill='white'))\n",
        "\n",
        "    lift_pen = 1\n",
        "    abs_x = 25 - min_x\n",
        "    abs_y = 25 - min_y\n",
        "\n",
        "    for i in range(len(data)):\n",
        "\n",
        "        x = float(data[i, 0]) / factor\n",
        "        y = float(data[i, 1]) / factor\n",
        "\n",
        "        prev_x = abs_x\n",
        "        prev_y = abs_y\n",
        "\n",
        "        abs_x += x\n",
        "        abs_y += y\n",
        "\n",
        "        if (lift_pen == 1):\n",
        "            p = \"M \" + str(abs_x) + \",\" + str(abs_y) + \" \"\n",
        "        else:\n",
        "            p = \"M +\" + str(prev_x) + \",\" + str(prev_y) + \\\n",
        "                \" L \" + str(abs_x) + \",\" + str(abs_y) + \" \"\n",
        "\n",
        "        lift_pen = data[i, 2]\n",
        "\n",
        "        the_color = \"black\"\n",
        "\n",
        "        if (color_data is not None):\n",
        "            the_color = \"rgb(\" + str(int(color_data[i, 0])) + \",\" + str(\n",
        "                int(color_data[i, 1])) + \",\" + str(int(color_data[i, 2])) + \")\"\n",
        "\n",
        "        dwg.add(dwg.path(p).stroke(the_color, stroke_width).fill(the_color))\n",
        "    dwg.save()\n",
        "    display(SVG(dwg.tostring()))\n",
        "\n",
        "        \n",
        "class DataLoader():\n",
        "    def __init__(self, batch_size=50, tsteps=300, scale_factor = 10, U_items=10, limit = 500, alphabet=\"default\"):\n",
        "        self.data_dir = \"./data\"\n",
        "        self.alphabet = alphabet\n",
        "        self.batch_size = batch_size\n",
        "        self.tsteps = tsteps\n",
        "        self.scale_factor = scale_factor # divide data by this factor\n",
        "        self.limit = limit # removes large noisy gaps in the data\n",
        "        self.U_items = U_items\n",
        "\n",
        "        data_file = os.path.join(self.data_dir, \"strokes_training_data_generation.cpkl\")\n",
        "        stroke_dir = self.data_dir+\"/lineStrokes\"\n",
        "        ascii_dir = self.data_dir+\"/ascii\"\n",
        "\n",
        "        if not (os.path.exists(data_file)) :\n",
        "            print (\"creating training data cpkl file from raw source\")\n",
        "            self.preprocess(stroke_dir, ascii_dir, data_file)\n",
        "\n",
        "        self.load_preprocessed(data_file)\n",
        "        self.reset_batch_pointer()\n",
        "\n",
        "    def preprocess(self, stroke_dir, ascii_dir, data_file):\n",
        "        # create data file from raw xml files from iam handwriting source.\n",
        "        print (\"Parsing dataset...\")\n",
        "        \n",
        "        # build the list of xml files\n",
        "        filelist = []\n",
        "        # Set the directory you want to start from\n",
        "        rootDir = stroke_dir\n",
        "        for dirName, subdirList, fileList in os.walk(rootDir):\n",
        "#             print('Found directory: %s' % dirName)\n",
        "            for fname in fileList:\n",
        "#                 print('\\t%s' % fname)\n",
        "                filelist.append(dirName+\"/\"+fname)\n",
        "\n",
        "        # function to read each individual xml file\n",
        "        def getStrokes(filename):\n",
        "            tree = ET.parse(filename)\n",
        "            root = tree.getroot()\n",
        "\n",
        "            result = []\n",
        "\n",
        "            x_offset = 1e20\n",
        "            y_offset = 1e20\n",
        "            y_height = 0\n",
        "            for i in range(1, 4):\n",
        "                x_offset = min(x_offset, float(root[0][i].attrib['x']))\n",
        "                y_offset = min(y_offset, float(root[0][i].attrib['y']))\n",
        "                y_height = max(y_height, float(root[0][i].attrib['y']))\n",
        "            y_height -= y_offset\n",
        "            x_offset -= 100\n",
        "            y_offset -= 100\n",
        "\n",
        "            for stroke in root[1].findall('Stroke'):\n",
        "                points = []\n",
        "                for point in stroke.findall('Point'):\n",
        "                    points.append([float(point.attrib['x'])-x_offset,float(point.attrib['y'])-y_offset])\n",
        "                result.append(points)\n",
        "            return result\n",
        "        \n",
        "        # function to read each individual xml file\n",
        "        def getAscii(filename, line_number):\n",
        "            with open(filename, \"r\") as f:\n",
        "                s = f.read()\n",
        "            s = s[s.find(\"CSR\"):]\n",
        "            if len(s.split(\"\\n\")) > line_number+2:\n",
        "                s = s.split(\"\\n\")[line_number+2]\n",
        "                return s\n",
        "            else:\n",
        "                return \"\"\n",
        "                \n",
        "        # converts a list of arrays into a 2d numpy int16 array\n",
        "        def convert_stroke_to_array(stroke):\n",
        "            n_point = 0\n",
        "            for i in range(len(stroke)):\n",
        "                n_point += len(stroke[i])\n",
        "            stroke_data = np.zeros((n_point, 3), dtype=np.int16)\n",
        "\n",
        "            prev_x = 0\n",
        "            prev_y = 0\n",
        "            counter = 0\n",
        "\n",
        "            for j in range(len(stroke)):\n",
        "                for k in range(len(stroke[j])):\n",
        "                    stroke_data[counter, 0] = int(stroke[j][k][0]) - prev_x\n",
        "                    stroke_data[counter, 1] = int(stroke[j][k][1]) - prev_y\n",
        "                    prev_x = int(stroke[j][k][0])\n",
        "                    prev_y = int(stroke[j][k][1])\n",
        "                    stroke_data[counter, 2] = 0\n",
        "                    if (k == (len(stroke[j])-1)): # end of stroke\n",
        "                        stroke_data[counter, 2] = 1\n",
        "                    counter += 1\n",
        "            return stroke_data\n",
        "\n",
        "        # build stroke database of every xml file inside iam database\n",
        "        strokes = []\n",
        "        asciis = []\n",
        "        for i in range(len(filelist)):\n",
        "            if (filelist[i][-3:] == 'xml'):\n",
        "                stroke_file = filelist[i]\n",
        "#                 print 'processing '+stroke_file\n",
        "                stroke = convert_stroke_to_array(getStrokes(stroke_file))\n",
        "                \n",
        "                ascii_file = stroke_file.replace(\"lineStrokes\",\"ascii\")[:-7] + \".txt\"\n",
        "                line_number = stroke_file[-6:-4]\n",
        "                line_number = int(line_number) - 1\n",
        "                ascii = getAscii(ascii_file, line_number)\n",
        "                if len(ascii) > 10:\n",
        "                    strokes.append(stroke)\n",
        "                    asciis.append(ascii)\n",
        "                else:\n",
        "                    print (\"======>>>> Line length was too short. Line was: \" + ascii)\n",
        "                \n",
        "        assert(len(strokes)==len(asciis)), \"There should be a 1:1 correspondence between stroke data and ascii labels.\"\n",
        "        f = open(data_file,\"wb\")\n",
        "        pickle.dump([strokes,asciis], f, protocol=2)\n",
        "        f.close()\n",
        "        print (\"Finished parsing dataset. Saved {} lines\".format(len(strokes)))\n",
        "\n",
        "\n",
        "    def load_preprocessed(self, data_file):\n",
        "        f = open(data_file,\"rb\")\n",
        "        [self.raw_stroke_data, self.raw_ascii_data] = pickle.load(f)\n",
        "        f.close()\n",
        "\n",
        "        # goes thru the list, and only keeps the text entries that have more than tsteps points\n",
        "        self.stroke_data = []\n",
        "        self.ascii_data = []\n",
        "        counter = 0\n",
        "\n",
        "        for i in range(len(self.raw_stroke_data)):\n",
        "            data = self.raw_stroke_data[i]\n",
        "            if len(data) > (self.tsteps+2):\n",
        "                # removes large gaps from the data\n",
        "                data = np.minimum(data, self.limit)\n",
        "                data = np.maximum(data, -self.limit)\n",
        "                data = np.array(data,dtype=np.float32)\n",
        "                data[:,0:2] /= self.scale_factor\n",
        "                \n",
        "                self.stroke_data.append(data)\n",
        "                self.ascii_data.append(self.raw_ascii_data[i])\n",
        "\n",
        "        # minus 1, since we want the ydata to be a shifted version of x data\n",
        "        self.num_batches = int(len(self.stroke_data) / self.batch_size)\n",
        "        print (\"Loaded dataset:\")\n",
        "        print (\"   -> {} individual data points\".format(len(self.stroke_data)))\n",
        "        print (\"   -> {} batches\".format(self.num_batches))\n",
        "\n",
        "    def next_batch(self):\n",
        "        # returns a randomised, tsteps sized portion of the training data\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "        ascii_list = []\n",
        "        for i in range(self.batch_size):\n",
        "            data = self.stroke_data[self.idx_perm[self.pointer]]\n",
        "            x_batch.append(np.copy(data[:self.tsteps]))\n",
        "            y_batch.append(np.copy(data[1:self.tsteps+1]))\n",
        "            ascii_list.append(self.ascii_data[self.idx_perm[self.pointer]])\n",
        "            self.tick_batch_pointer()\n",
        "        one_hots = [self.one_hot(s) for s in ascii_list]\n",
        "        return x_batch, y_batch, ascii_list, one_hots\n",
        "    \n",
        "    def one_hot(self, s):\n",
        "        #index position 0 means \"unknown\"\n",
        "        if self.alphabet is \"default\":\n",
        "            alphabet = \" abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\"\n",
        "        seq = [alphabet.find(char) + 1 for char in s]\n",
        "        if len(seq) >= self.U_items:\n",
        "            seq = seq[:self.U_items]\n",
        "        else:\n",
        "            seq = seq + [0]*(self.U_items - len(seq))\n",
        "        one_hot = np.zeros((self.U_items,len(alphabet)+1))\n",
        "        one_hot[np.arange(self.U_items),seq] = 1\n",
        "        return one_hot\n",
        "\n",
        "    def tick_batch_pointer(self):\n",
        "        self.pointer += 1\n",
        "        if (self.pointer >= len(self.stroke_data)):\n",
        "            self.reset_batch_pointer()\n",
        "    def reset_batch_pointer(self):\n",
        "        self.idx_perm = np.random.permutation(len(self.stroke_data))\n",
        "        self.pointer = 0\n",
        "        print (\"pointer reset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkOlcXzU4sBV",
        "outputId": "5723c66e-5fd3-4ad4-cbe1-430eaa336681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:311: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:311: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<ipython-input-4-a01dd65da06b>:311: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if self.alphabet is \"default\":\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "with open('data/strokes_training_data_generation.cpkl', 'rb') as f:\n",
        "    data = pickle.load(f)"
      ],
      "metadata": {
        "id": "pxpVV3UfhhTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5zsfDHoiKm0",
        "outputId": "e799fb7b-b993-456f-aad7-4777ed601a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def line_plot(strokes, title):\n",
        "    plt.figure(figsize=(20,2))\n",
        "    eos_preds = np.where(strokes[:,-1] == 1)\n",
        "    eos_preds = [0] + list(eos_preds[0]) + [-1] #add start and end indices\n",
        "    for i in range(len(eos_preds)-1):\n",
        "        start = eos_preds[i]+1\n",
        "        stop = eos_preds[i+1]\n",
        "        plt.plot(strokes[start:stop,0], strokes[start:stop,1],'b-', linewidth=2.0)\n",
        "    plt.title(title)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.show()\n",
        "\n",
        "def one_hot(s):\n",
        "    #index position 0 means \"unknown\"\n",
        "    alphabet = \" abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890\"\n",
        "    seq = [alphabet.find(char) + 1 for char in s]\n",
        "\n",
        "    one_hot = np.zeros((len(s),len(alphabet)+1))\n",
        "    one_hot[np.arange(len(s)),seq] = 1\n",
        "    return one_hot\n",
        "\n",
        "def plot_heatmaps(Phis, Ws):\n",
        "    plt.figure(figsize=(16,4))\n",
        "    plt.subplot(121)\n",
        "    plt.title('Phis', fontsize=20)\n",
        "    plt.xlabel(\"time steps\", fontsize=15)\n",
        "    plt.ylabel(\"ascii #\", fontsize=15)\n",
        "    \n",
        "    plt.imshow(Phis, interpolation='nearest', aspect='auto', cmap=cm.jet)\n",
        "    plt.subplot(122)\n",
        "    plt.title('Soft attention window', fontsize=20)\n",
        "    plt.xlabel(\"time steps\", fontsize=15)\n",
        "    plt.ylabel(\"one-hot vector\", fontsize=15)\n",
        "    plt.imshow(Ws, interpolation='nearest', aspect='auto', cmap=cm.jet)\n",
        "\n",
        "    display(plt.gcf())\n",
        "    \n",
        "\n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lqwtUcU-5KN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8jcobLP-iIqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HandwritingSynthesisModel(nn.Module):\n",
        "    def __init__(self, hidden_size = 256, n_gaussians = 20, Kmixtures = 10, dropout = 0.2, alphabet_size = 64):\n",
        "        super(HandwritingSynthesisModel, self).__init__()\n",
        "        \n",
        "        self.Kmixtures = Kmixtures\n",
        "        self.n_gaussians = n_gaussians\n",
        "        self.alphabet_size = alphabet_size\n",
        "        \n",
        "        self.hidden_size1 = hidden_size\n",
        "        self.hidden_size2 = hidden_size\n",
        "        self.hidden_size3 = hidden_size\n",
        "        \n",
        "        # input_size1 includes x, y, eos and len(w_t_1) given by alphabet_size (see eq 52)\n",
        "        self.input_size1 = 3 + alphabet_size\n",
        "        \n",
        "        # input_size2 includes x, y, eos, len(w_t) given by alphabet_size (see eq 47) and hidden_size1\n",
        "        self.input_size2 = 3 + alphabet_size + self.hidden_size1\n",
        "        \n",
        "        # input_size3 includes x, y, eos, len(w_t) given by alphabet_size (see eq 47) and hidden_size2\n",
        "        self.input_size3 = 3 + alphabet_size + self.hidden_size2\n",
        "        \n",
        "        # See eq 52-53 to understand the input_sizes\n",
        "        self.lstm1 = nn.LSTMCell(input_size= self.input_size1 , hidden_size = self.hidden_size1)\n",
        "        self.lstm2 = nn.LSTMCell(input_size= self.input_size2 , hidden_size = self.hidden_size2)\n",
        "        self.lstm3 = nn.LSTMCell(input_size= self.input_size3 , hidden_size = self.hidden_size3)\n",
        "        \n",
        "        # Window layer takes hidden layer of LSTM1 as input and outputs 3 * Kmixtures vectors\n",
        "        self.window_layer = nn.Linear(self.hidden_size1, 3 * Kmixtures)\n",
        "        \n",
        "        # For gaussian mixtures\n",
        "        self.z_e = nn.Linear(hidden_size, 1)\n",
        "        self.z_pi = nn.Linear(hidden_size, n_gaussians)\n",
        "        self.z_mu1 = nn.Linear(hidden_size, n_gaussians)\n",
        "        self.z_mu2 = nn.Linear(hidden_size, n_gaussians)\n",
        "        self.z_sigma1 = nn.Linear(hidden_size, n_gaussians)\n",
        "        self.z_sigma2 = nn.Linear(hidden_size, n_gaussians)\n",
        "        self.z_rho = nn.Linear(hidden_size, n_gaussians)\n",
        "        \n",
        "        # Bias for sampling\n",
        "        self.bias = 0\n",
        "        \n",
        "        # Saves hidden and cell states\n",
        "        self.LSTMstates = None\n",
        "        \n",
        "        \n",
        "    def forward(self, x, c, generate = False):\n",
        "        # sequence length\n",
        "        sequence_length = x.shape[0]\n",
        "        \n",
        "        # number of batches\n",
        "        n_batch = x.shape[1]\n",
        "        \n",
        "        # Soft window vector w at t-1\n",
        "        w_t_1 = torch.ones(n_batch, self.alphabet_size) # torch.Size([n_batch, len(alphabet)])\n",
        "        \n",
        "        # Hidden and cell state for LSTM1\n",
        "        h1_t = torch.zeros(n_batch, self.hidden_size1) # torch.Size([n_batch, hidden_size1])\n",
        "        c1_t = torch.zeros(n_batch, self.hidden_size1) # torch.Size([n_batch, hidden_size1])\n",
        "        \n",
        "        # Kappa at t-1\n",
        "        kappa_t_1 = torch.zeros(n_batch, Kmixtures) # torch.Size([n_batch, Kmixtures])\n",
        "        \n",
        "        # Hidden and cell state for LSTM2\n",
        "        h2_t = torch.zeros(n_batch, self.hidden_size2) # torch.Size([n_batch, hidden_size2])\n",
        "        c2_t = torch.zeros(n_batch, self.hidden_size2) # torch.Size([n_batch, hidden_size2])\n",
        "        \n",
        "        # Hidden and cell state for LSTM3\n",
        "        h3_t = torch.zeros(n_batch, self.hidden_size3) # torch.Size([n_batch, hidden_size3])\n",
        "        c3_t = torch.zeros(n_batch, self.hidden_size3) # torch.Size([n_batch, hidden_size3])\n",
        "        \n",
        "        if generate and self.LSTMstates != None:\n",
        "            h1_t = self.LSTMstates[\"h1_t\"]\n",
        "            c1_t = self.LSTMstates[\"c1_t\"]\n",
        "            h2_t = self.LSTMstates[\"h2_t\"]\n",
        "            c2_t = self.LSTMstates[\"c2_t\"]\n",
        "            h3_t = self.LSTMstates[\"h3_t\"]\n",
        "            c3_t = self.LSTMstates[\"c3_t\"]\n",
        "            w_t_1 = self.LSTMstates[\"w_t_1\"]\n",
        "            kappa_t_1 = self.LSTMstates[\"kappa_t_1\"]\n",
        "        \n",
        "        out = torch.zeros(sequence_length, n_batch, self.hidden_size3)\n",
        "        \n",
        "        # Phis and Ws allow to plot heatmaps of phi et w over time\n",
        "        self.Phis = torch.zeros(sequence_length, c.shape[1])\n",
        "        self.Ws = torch.zeros(sequence_length, self.alphabet_size)\n",
        "        \n",
        "        if use_cuda:\n",
        "            w_t_1 = w_t_1.cuda()\n",
        "            \n",
        "            h1_t = h1_t.cuda()\n",
        "            c1_t = c1_t.cuda()\n",
        "            \n",
        "            kappa_t_1 = kappa_t_1.cuda()\n",
        "            \n",
        "            h2_t = h2_t.cuda()\n",
        "            c2_t = c2_t.cuda()\n",
        "            \n",
        "            h3_t = h3_t.cuda()\n",
        "            c3_t = c3_t.cuda()\n",
        "            \n",
        "            out = out.cuda()\n",
        "            \n",
        "        for i in range(sequence_length):\n",
        "            # ===== Computing 1st layer =====\n",
        "            input_lstm1 = torch.cat((x[i], w_t_1), 1) # torch.Size([n_batch, input_size1])\n",
        "            h1_t, c1_t = self.lstm1(input_lstm1, (h1_t, c1_t)) # torch.Size([n_batch, hidden_size1])\n",
        "            \n",
        "            # ===== Computing soft window =====\n",
        "            window = self.window_layer(h1_t)\n",
        "            \n",
        "            # splits exp(window) into 3 tensors of torch.Size([n_batch, Kmixtures])\n",
        "            # Eqs 48-51 of the paper\n",
        "            alpha_t, beta_t, kappa_t = torch.chunk( torch.exp(window), 3, dim=1) \n",
        "            kappa_t = 0.1 * kappa_t + kappa_t_1\n",
        "            \n",
        "            # updates kappa_t_1 for next iteration\n",
        "            kappa_t_1 = kappa_t\n",
        "            \n",
        "            u = torch.arange(0,c.shape[1], out=kappa_t.new()).view(-1,1,1) # torch.Size([U_items, 1, 1])\n",
        "            \n",
        "            # Computing Phi(t, u)\n",
        "            # Eq 46 of the paper\n",
        "            # Keep in mind the (kappa_t - u).shape is torch.Size([U_items, n_batch, Kmixtures])\n",
        "            # For example :\n",
        "            ## (kappa_t - u)[0, 0, :] gives kappa_t[0, :]\n",
        "            ## (kappa_t - u)[1, 0, :] gives kappa_t[0, :] - 1\n",
        "            ## etc\n",
        "            Phi = alpha_t * torch.exp(- beta_t * (kappa_t - u) ** 2) # torch.Size([U_items, n_batch, Kmixtures])\n",
        "            Phi = torch.sum(Phi, dim = 2) # torch.Size([U_items, n_batch])  \n",
        "            Phi = torch.unsqueeze(Phi, 0) # torch.Size([1, U_items, n_batch])\n",
        "            Phi = Phi.permute(2, 0, 1) # torch.Size([n_batch, 1, U_items])\n",
        "            \n",
        "            self.Phis[i, :] = Phi[0, 0, :] # To plot heatmaps\n",
        "            \n",
        "            # Computing wt \n",
        "            # Eq 47 of the paper\n",
        "            w_t = torch.matmul(Phi, c) # torch.Size([n_batch, 1, len(alphabet)])\n",
        "            w_t = torch.squeeze(w_t, 1) # torch.Size([n_batch, len(alphabet)])\n",
        "            \n",
        "            self.Ws[i, :] = w_t[0, :] # To plot heatmaps\n",
        "            \n",
        "            # Update w_t_1 for next iteration\n",
        "            w_t_1 = w_t\n",
        "            \n",
        "            # ===== Computing 2nd layer =====\n",
        "            input_lstm2 = torch.cat((x[i], w_t, h1_t), 1) # torch.Size([n_batch, 3 + alphabet_size + hidden_size1])\n",
        "            h2_t, c2_t = self.lstm2(input_lstm2, (h2_t, c2_t)) \n",
        "            \n",
        "            \n",
        "            # ===== Computing 3rd layer =====\n",
        "            input_lstm3 = torch.cat((x[i], w_t, h2_t), 1) # torch.Size([n_batch, 3 + alphabet_size + hidden_size2])\n",
        "            h3_t, c3_t = self.lstm3(input_lstm3, (h3_t, c3_t))\n",
        "            out[i, :, :] = h3_t\n",
        "            \n",
        "        # ===== Computing MDN =====\n",
        "        es = self.z_e(out)\n",
        "        # print(\"es shape \", es.shape) # -> torch.Size([sequence_length, batch, 1])\n",
        "        es = 1 / (1 + torch.exp(es))\n",
        "        # print(\"es shape\", es.shape) # -> torch.Size([sequence_length, batch, 1])\n",
        "\n",
        "        pis = self.z_pi(out) * (1 + self.bias)\n",
        "        # print(\"pis shape \", pis.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "        pis = torch.softmax(pis, 2)\n",
        "        # print(pis.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "\n",
        "        mu1s = self.z_mu1(out) \n",
        "        mu2s = self.z_mu2(out)\n",
        "        # print(\"mu shape :  \", mu1s.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "\n",
        "        sigma1s = self.z_sigma1(out)\n",
        "        sigma2s = self.z_sigma2(out)\n",
        "        # print(\"sigmas shape \", sigma1s.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "        sigma1s = torch.exp(sigma1s - self.bias)\n",
        "        sigma2s = torch.exp(sigma2s - self.bias)\n",
        "        # print(sigma1s.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "\n",
        "        rhos = self.z_rho(out)\n",
        "        rhos = torch.tanh(rhos)\n",
        "        # print(\"rhos shape \", rhos.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "\n",
        "        es = es.squeeze(2) \n",
        "        # print(\"es shape \", es.shape) # -> torch.Size([sequence_length, batch])\n",
        "\n",
        "        # Hidden and cell states\n",
        "        if generate:\n",
        "            self.LSTMstates = {\"h1_t\": h1_t,\n",
        "                              \"c1_t\": c1_t,\n",
        "                              \"h2_t\": h2_t,\n",
        "                              \"c2_t\": c2_t,\n",
        "                              \"h3_t\": h3_t,\n",
        "                              \"c3_t\": c3_t,\n",
        "                              \"w_t_1\": w_t_1,\n",
        "                              \"kappa_t_1\": kappa_t_1}\n",
        "        \n",
        "        return es, pis, mu1s, mu2s, sigma1s, sigma2s, rhos\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def generate_sample(self, mu1, mu2, sigma1, sigma2, rho):\n",
        "        mean = [mu1, mu2]\n",
        "        cov = [[sigma1 ** 2, rho * sigma1 * sigma2], [rho * sigma1 * sigma2, sigma2 ** 2]]\n",
        "        \n",
        "        x = np.float32(np.random.multivariate_normal(mean, cov, 1))\n",
        "        return torch.from_numpy(x)\n",
        "        \n",
        "        \n",
        "    def generate_sequence(self, x0, c0, bias):\n",
        "        sequence = x0\n",
        "        sample = x0\n",
        "        sequence_length = c0.shape[1] * 25\n",
        "        \n",
        "        print(\"Generating sequence ...\")\n",
        "        self.bias = bias\n",
        "        f = FloatProgress(min=0, max=sequence_length)\n",
        "        display(f)\n",
        "\n",
        "        for i in range(sequence_length):\n",
        "            es, pis, mu1s, mu2s, sigma1s, sigma2s, rhos = self.forward(sample, c0, True)\n",
        "            \n",
        "            # Selecting a mixture \n",
        "            pi_idx = np.random.choice(range(self.n_gaussians), p=pis[-1, 0, :].detach().cpu().numpy())\n",
        "            \n",
        "            # taking last parameters from sequence corresponding to chosen gaussian\n",
        "            mu1 = mu1s[-1, :, pi_idx].item()\n",
        "            mu2 = mu2s[-1, :, pi_idx].item()\n",
        "            sigma1 = sigma1s[-1, :, pi_idx].item()\n",
        "            sigma2 = sigma2s[-1, :, pi_idx].item()\n",
        "            rho = rhos[-1, :, pi_idx].item()\n",
        "            \n",
        "            prediction = self.generate_sample(mu1, mu2, sigma1, sigma2, rho)\n",
        "            eos = torch.distributions.bernoulli.Bernoulli(torch.tensor([es[-1, :].item()])).sample()\n",
        "            \n",
        "            sample = torch.zeros_like(x0) # torch.Size([1, 1, 3])\n",
        "            sample[0, 0, 0] = prediction[0, 0]\n",
        "            sample[0, 0, 1] = prediction[0, 1]\n",
        "            sample[0, 0, 2] = eos\n",
        "            \n",
        "            sequence = torch.cat((sequence, sample), 0) # torch.Size([sequence_length, 1, 3])\n",
        "            \n",
        "            f.value += 1\n",
        "        \n",
        "        self.bias = 0\n",
        "        self.LSTMstates = None\n",
        "        \n",
        "        return sequence.squeeze(1).detach().cpu().numpy()\n"
      ],
      "metadata": {
        "id": "_hLEKgpP6b-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gaussianMixture(y, pis, mu1s, mu2s, sigma1s, sigma2s, rhos):\n",
        "    n_mixtures = pis.size(2)\n",
        "    \n",
        "    # Takes x1 and repeats it over the number of gaussian mixtures\n",
        "    x1 = y[:,:, 0].repeat(n_mixtures, 1, 1).permute(1, 2, 0) \n",
        "    # print(\"x1 shape \", x1.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "    \n",
        "    # first term of Z (eq 25)\n",
        "    x1norm = ((x1 - mu1s) ** 2) / (sigma1s ** 2 )\n",
        "    # print(\"x1norm shape \", x1.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "    \n",
        "    x2 = y[:,:, 1].repeat(n_mixtures, 1, 1).permute(1, 2, 0)  \n",
        "    # print(\"x2 shape \", x2.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "    \n",
        "    # second term of Z (eq 25)\n",
        "    x2norm = ((x2 - mu2s) ** 2) / (sigma2s ** 2 )\n",
        "    # print(\"x2norm shape \", x2.shape) # -> torch.Size([sequence_length, batch, n_gaussians])\n",
        "    \n",
        "    # third term of Z (eq 25)\n",
        "    coxnorm = 2 * rhos * (x1 - mu1s) * (x2 - mu2s) / (sigma1s * sigma2s) \n",
        "    \n",
        "    # Computing Z (eq 25)\n",
        "    Z = x1norm + x2norm - coxnorm\n",
        "    \n",
        "    # Gaussian bivariate (eq 24)\n",
        "    N = torch.exp(-Z / (2 * (1 - rhos ** 2))) / (2 * np.pi * sigma1s * sigma2s * (1 - rhos ** 2) ** 0.5) \n",
        "    # print(\"N shape \", N.shape) # -> torch.Size([sequence_length, batch, n_gaussians]) \n",
        "    \n",
        "    # Pr is the result of eq 23 without the eos part\n",
        "    Pr = pis * N \n",
        "    # print(\"Pr shape \", Pr.shape) # -> torch.Size([sequence_length, batch, n_gaussians])   \n",
        "    Pr = torch.sum(Pr, dim=2) \n",
        "    # print(\"Pr shape \", Pr.shape) # -> torch.Size([sequence_length, batch])   \n",
        "    \n",
        "    if use_cuda:\n",
        "        Pr = Pr.cuda()\n",
        "    \n",
        "    return Pr"
      ],
      "metadata": {
        "id": "E7sXeSbC6o8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(Pr, y, es):\n",
        "    loss1 = - torch.log(Pr + eps) # -> torch.Size([sequence_length, batch])    \n",
        "    bernouilli = torch.zeros_like(es) # -> torch.Size([sequence_length, batch])\n",
        "    \n",
        "    bernouilli = y[:, :, 2] * es + (1 - y[:, :, 2]) * (1 - es)\n",
        "    \n",
        "    loss2 = - torch.log(bernouilli + eps)\n",
        "    loss = loss1 + loss2 \n",
        "    # print(\"loss shape\", loss.shape) # -> torch.Size([sequence_length, batch])  \n",
        "    loss = torch.sum(loss, 0) \n",
        "    # print(\"loss shape\", loss.shape) # -> torch.Size([batch]) \n",
        "    \n",
        "    return torch.mean(loss);\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "x_u9mXC06rlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(n_batch, sequence_length, 20, U_items=U_items)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCl48T756tU5",
        "outputId": "472bb15e-63bf-4dae-8e7e-e8605f251205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset:\n",
            "   -> 10974 individual data points\n",
            "   -> 548 batches\n",
            "pointer reset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader.reset_batch_pointer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoKiye5v64oA",
        "outputId": "55a71169-1327-421e-85c7-f0d45f9f9745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataLoader.reset_batch_pointer of <__main__.DataLoader object at 0x7f10c81c0b50>>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader.num_batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp3AT1Q97P6w",
        "outputId": "9f9271fe-0b4f-40b5-e722-55536e09bd59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "548"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader.next_batch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzcnFs6Z7UBQ",
        "outputId": "367f1a98-10d3-470d-b47b-2ea1f43923a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([[ 5.25,  6.75,  0.  ],\n",
              "         [-0.25,  1.  ,  0.  ],\n",
              "         [ 1.1 , -0.3 ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.85,  0.05,  0.  ],\n",
              "         [ 1.05, -0.05,  0.  ],\n",
              "         [ 0.95,  0.1 ,  0.  ]], dtype=float32), array([[12.95, 15.6 ,  0.  ],\n",
              "         [-0.05,  0.  ,  0.  ],\n",
              "         [-0.1 ,  0.  ,  0.  ],\n",
              "         ...,\n",
              "         [-0.2 ,  0.9 ,  1.  ],\n",
              "         [-0.8 ,  3.85,  0.  ],\n",
              "         [-0.3 ,  2.6 ,  0.  ]], dtype=float32), array([[12.65, 17.8 ,  1.  ],\n",
              "         [ 0.3 ,  2.65,  0.  ],\n",
              "         [ 0.4 ,  2.4 ,  0.  ],\n",
              "         ...,\n",
              "         [-1.1 ,  0.  ,  0.  ],\n",
              "         [-1.  ,  0.5 ,  0.  ],\n",
              "         [-1.  ,  0.95,  0.  ]], dtype=float32), array([[13.8 ,  5.  ,  0.  ],\n",
              "         [-0.05,  0.15,  0.  ],\n",
              "         [-0.25,  0.25,  0.  ],\n",
              "         ...,\n",
              "         [ 2.65, -0.95,  0.  ],\n",
              "         [ 2.45, -1.2 ,  1.  ],\n",
              "         [19.65, -0.4 ,  0.  ]], dtype=float32), array([[ 5.15,  5.  ,  0.  ],\n",
              "         [-0.15,  0.65,  0.  ],\n",
              "         [ 0.2 ,  1.2 ,  0.  ],\n",
              "         ...,\n",
              "         [-0.3 ,  1.05,  0.  ],\n",
              "         [-0.2 ,  1.4 ,  0.  ],\n",
              "         [ 0.  ,  1.5 ,  0.  ]], dtype=float32), array([[ 5.  ,  8.1 ,  0.  ],\n",
              "         [ 0.  ,  0.  ,  0.  ],\n",
              "         [ 0.  ,  0.2 ,  0.  ],\n",
              "         ...,\n",
              "         [-0.05, -1.25,  0.  ],\n",
              "         [ 0.1 , -1.05,  0.  ],\n",
              "         [ 0.05, -1.3 ,  0.  ]], dtype=float32), array([[10.5 ,  5.  ,  0.  ],\n",
              "         [-0.5 ,  0.75,  0.  ],\n",
              "         [-0.2 ,  1.35,  0.  ],\n",
              "         ...,\n",
              "         [ 0.65,  0.75,  0.  ],\n",
              "         [ 0.55,  1.4 ,  0.  ],\n",
              "         [ 0.5 ,  1.6 ,  0.  ]], dtype=float32), array([[ 7.35,  6.6 ,  0.  ],\n",
              "         [ 0.  ,  0.2 ,  0.  ],\n",
              "         [ 0.  ,  0.  ,  0.  ],\n",
              "         ...,\n",
              "         [-1.3 ,  1.2 ,  0.  ],\n",
              "         [-0.5 ,  0.1 ,  0.  ],\n",
              "         [-0.25, -1.5 ,  0.  ]], dtype=float32), array([[ 6.6 , 12.8 ,  0.  ],\n",
              "         [ 0.15,  0.  ,  0.  ],\n",
              "         [ 0.05,  0.2 ,  0.  ],\n",
              "         ...,\n",
              "         [ 1.45, -0.6 ,  0.  ],\n",
              "         [ 1.3 , -0.3 ,  0.  ],\n",
              "         [ 1.35,  0.2 ,  0.  ]], dtype=float32), array([[ 8.7 , 10.9 ,  0.  ],\n",
              "         [-0.1 , -0.1 ,  0.  ],\n",
              "         [-0.15, -0.15,  0.  ],\n",
              "         ...,\n",
              "         [-0.85,  1.1 ,  0.  ],\n",
              "         [-0.65,  1.35,  0.  ],\n",
              "         [-1.05,  0.7 ,  0.  ]], dtype=float32), array([[ 5.25, 13.95,  0.  ],\n",
              "         [-0.1 ,  0.8 ,  0.  ],\n",
              "         [-0.15,  1.2 ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.4 , -0.85,  0.  ],\n",
              "         [-0.1 , -1.3 ,  0.  ],\n",
              "         [-0.25, -1.35,  0.  ]], dtype=float32), array([[11.5 ,  5.25,  0.  ],\n",
              "         [-0.1 ,  1.4 ,  0.  ],\n",
              "         [-0.25,  1.75,  0.  ],\n",
              "         ...,\n",
              "         [ 2.05,  0.7 ,  0.  ],\n",
              "         [ 1.8 ,  0.15,  0.  ],\n",
              "         [ 1.4 , -0.35,  0.  ]], dtype=float32), array([[ 6.  , 12.4 ,  0.  ],\n",
              "         [-0.2 ,  0.2 ,  0.  ],\n",
              "         [ 0.1 ,  0.4 ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.45,  1.05,  0.  ],\n",
              "         [ 0.1 ,  1.25,  0.  ],\n",
              "         [-0.3 ,  1.35,  0.  ]], dtype=float32), array([[ 6.2 , 16.1 ,  0.  ],\n",
              "         [-0.25,  0.95,  0.  ],\n",
              "         [-0.2 ,  1.6 ,  0.  ],\n",
              "         ...,\n",
              "         [-0.05,  0.9 ,  0.  ],\n",
              "         [-0.3 ,  1.3 ,  0.  ],\n",
              "         [-0.15,  1.65,  0.  ]], dtype=float32), array([[ 5.9 , 13.6 ,  0.  ],\n",
              "         [ 0.  ,  0.8 ,  0.  ],\n",
              "         [-0.25,  1.  ,  0.  ],\n",
              "         ...,\n",
              "         [-0.7 ,  0.65,  0.  ],\n",
              "         [-0.3 ,  0.6 ,  0.  ],\n",
              "         [-0.55,  0.25,  0.  ]], dtype=float32), array([[ 5.05, 15.85,  0.  ],\n",
              "         [-0.05,  0.45,  0.  ],\n",
              "         [ 0.15,  1.  ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.95,  0.7 ,  0.  ],\n",
              "         [ 0.5 ,  1.1 ,  0.  ],\n",
              "         [ 0.1 ,  1.3 ,  0.  ]], dtype=float32), array([[ 7.15, 11.6 ,  0.  ],\n",
              "         [-0.2 , -0.05,  0.  ],\n",
              "         [ 0.  ,  0.  ,  0.  ],\n",
              "         ...,\n",
              "         [-0.05, -0.55,  0.  ],\n",
              "         [ 0.2 , -1.45,  0.  ],\n",
              "         [ 0.65, -1.4 ,  0.  ]], dtype=float32), array([[ 5.15, 20.75,  0.  ],\n",
              "         [ 0.05,  0.85,  0.  ],\n",
              "         [ 0.  ,  1.2 ,  0.  ],\n",
              "         ...,\n",
              "         [-0.15,  0.15,  1.  ],\n",
              "         [ 6.1 , -8.  ,  0.  ],\n",
              "         [ 0.05, -0.15,  0.  ]], dtype=float32), array([[15.35, 25.  ,  0.  ],\n",
              "         [-0.2 , -0.2 ,  0.  ],\n",
              "         [-0.3 , -0.4 ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.  ,  0.1 ,  0.  ],\n",
              "         [ 0.2 ,  0.35,  0.  ],\n",
              "         [ 0.35,  0.9 ,  0.  ]], dtype=float32), array([[ 8.65, 25.  ,  0.  ],\n",
              "         [-0.55, -0.4 ,  0.  ],\n",
              "         [-0.15,  0.  ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.35,  0.85,  0.  ],\n",
              "         [ 0.5 ,  0.35,  0.  ],\n",
              "         [-0.15, -0.15,  0.  ]], dtype=float32)],\n",
              " [array([[-0.25,  1.  ,  0.  ],\n",
              "         [ 1.1 , -0.3 ,  0.  ],\n",
              "         [ 2.4 , -0.05,  0.  ],\n",
              "         ...,\n",
              "         [ 1.05, -0.05,  0.  ],\n",
              "         [ 0.95,  0.1 ,  0.  ],\n",
              "         [ 0.6 ,  0.15,  0.  ]], dtype=float32), array([[-0.05,  0.  ,  0.  ],\n",
              "         [-0.1 ,  0.  ,  0.  ],\n",
              "         [-0.05,  0.  ,  0.  ],\n",
              "         ...,\n",
              "         [-0.8 ,  3.85,  0.  ],\n",
              "         [-0.3 ,  2.6 ,  0.  ],\n",
              "         [-0.85,  2.65,  0.  ]], dtype=float32), array([[ 0.3 ,  2.65,  0.  ],\n",
              "         [ 0.4 ,  2.4 ,  0.  ],\n",
              "         [ 0.45,  2.75,  0.  ],\n",
              "         ...,\n",
              "         [-1.  ,  0.5 ,  0.  ],\n",
              "         [-1.  ,  0.95,  0.  ],\n",
              "         [-0.5 ,  1.35,  0.  ]], dtype=float32), array([[-0.05,  0.15,  0.  ],\n",
              "         [-0.25,  0.25,  0.  ],\n",
              "         [-0.45,  0.6 ,  0.  ],\n",
              "         ...,\n",
              "         [ 2.45, -1.2 ,  1.  ],\n",
              "         [19.65, -0.4 ,  0.  ],\n",
              "         [-0.05, -0.25,  0.  ]], dtype=float32), array([[-0.15,  0.65,  0.  ],\n",
              "         [ 0.2 ,  1.2 ,  0.  ],\n",
              "         [ 0.05,  1.05,  0.  ],\n",
              "         ...,\n",
              "         [-0.2 ,  1.4 ,  0.  ],\n",
              "         [ 0.  ,  1.5 ,  0.  ],\n",
              "         [ 0.45,  1.2 ,  0.  ]], dtype=float32), array([[ 0.  ,  0.  ,  0.  ],\n",
              "         [ 0.  ,  0.2 ,  0.  ],\n",
              "         [ 0.05,  0.4 ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.1 , -1.05,  0.  ],\n",
              "         [ 0.05, -1.3 ,  0.  ],\n",
              "         [-0.15, -1.15,  0.  ]], dtype=float32), array([[-0.5 ,  0.75,  0.  ],\n",
              "         [-0.2 ,  1.35,  0.  ],\n",
              "         [-0.1 ,  1.8 ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.55,  1.4 ,  0.  ],\n",
              "         [ 0.5 ,  1.6 ,  0.  ],\n",
              "         [ 0.9 ,  1.85,  0.  ]], dtype=float32), array([[ 0.  ,  0.2 ,  0.  ],\n",
              "         [ 0.  ,  0.  ,  0.  ],\n",
              "         [-0.1 ,  0.8 ,  0.  ],\n",
              "         ...,\n",
              "         [-0.5 ,  0.1 ,  0.  ],\n",
              "         [-0.25, -1.5 ,  0.  ],\n",
              "         [ 0.3 , -2.7 ,  0.  ]], dtype=float32), array([[ 0.15,  0.  ,  0.  ],\n",
              "         [ 0.05,  0.2 ,  0.  ],\n",
              "         [-0.05,  0.35,  0.  ],\n",
              "         ...,\n",
              "         [ 1.3 , -0.3 ,  0.  ],\n",
              "         [ 1.35,  0.2 ,  0.  ],\n",
              "         [ 0.95, -0.1 ,  0.  ]], dtype=float32), array([[-0.1 , -0.1 ,  0.  ],\n",
              "         [-0.15, -0.15,  0.  ],\n",
              "         [-0.1 , -0.05,  0.  ],\n",
              "         ...,\n",
              "         [-0.65,  1.35,  0.  ],\n",
              "         [-1.05,  0.7 ,  0.  ],\n",
              "         [-0.95,  0.35,  0.  ]], dtype=float32), array([[-0.1 ,  0.8 ,  0.  ],\n",
              "         [-0.15,  1.2 ,  0.  ],\n",
              "         [ 0.1 ,  1.8 ,  0.  ],\n",
              "         ...,\n",
              "         [-0.1 , -1.3 ,  0.  ],\n",
              "         [-0.25, -1.35,  0.  ],\n",
              "         [-0.5 , -1.1 ,  1.  ]], dtype=float32), array([[-0.1 ,  1.4 ,  0.  ],\n",
              "         [-0.25,  1.75,  0.  ],\n",
              "         [-0.25,  2.2 ,  0.  ],\n",
              "         ...,\n",
              "         [ 1.8 ,  0.15,  0.  ],\n",
              "         [ 1.4 , -0.35,  0.  ],\n",
              "         [ 0.95, -0.75,  0.  ]], dtype=float32), array([[-0.2 ,  0.2 ,  0.  ],\n",
              "         [ 0.1 ,  0.4 ,  0.  ],\n",
              "         [ 0.05,  0.8 ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.1 ,  1.25,  0.  ],\n",
              "         [-0.3 ,  1.35,  0.  ],\n",
              "         [-0.7 ,  1.25,  0.  ]], dtype=float32), array([[-0.25,  0.95,  0.  ],\n",
              "         [-0.2 ,  1.6 ,  0.  ],\n",
              "         [-0.25,  1.8 ,  0.  ],\n",
              "         ...,\n",
              "         [-0.3 ,  1.3 ,  0.  ],\n",
              "         [-0.15,  1.65,  0.  ],\n",
              "         [-0.1 ,  1.6 ,  0.  ]], dtype=float32), array([[ 0.  ,  0.8 ,  0.  ],\n",
              "         [-0.25,  1.  ,  0.  ],\n",
              "         [-0.3 ,  1.45,  0.  ],\n",
              "         ...,\n",
              "         [-0.3 ,  0.6 ,  0.  ],\n",
              "         [-0.55,  0.25,  0.  ],\n",
              "         [-0.05,  0.2 ,  0.  ]], dtype=float32), array([[-0.05,  0.45,  0.  ],\n",
              "         [ 0.15,  1.  ,  0.  ],\n",
              "         [ 0.1 ,  1.4 ,  0.  ],\n",
              "         ...,\n",
              "         [ 0.5 ,  1.1 ,  0.  ],\n",
              "         [ 0.1 ,  1.3 ,  0.  ],\n",
              "         [ 0.25,  1.55,  0.  ]], dtype=float32), array([[-0.2 , -0.05,  0.  ],\n",
              "         [ 0.  ,  0.  ,  0.  ],\n",
              "         [ 0.15,  0.05,  0.  ],\n",
              "         ...,\n",
              "         [ 0.2 , -1.45,  0.  ],\n",
              "         [ 0.65, -1.4 ,  0.  ],\n",
              "         [ 0.75, -1.2 ,  0.  ]], dtype=float32), array([[ 0.05,  0.85,  0.  ],\n",
              "         [ 0.  ,  1.2 ,  0.  ],\n",
              "         [ 0.05,  1.25,  0.  ],\n",
              "         ...,\n",
              "         [ 6.1 , -8.  ,  0.  ],\n",
              "         [ 0.05, -0.15,  0.  ],\n",
              "         [ 0.15, -0.25,  0.  ]], dtype=float32), array([[-0.2 , -0.2 ,  0.  ],\n",
              "         [-0.3 , -0.4 ,  0.  ],\n",
              "         [-0.5 , -0.35,  0.  ],\n",
              "         ...,\n",
              "         [ 0.2 ,  0.35,  0.  ],\n",
              "         [ 0.35,  0.9 ,  0.  ],\n",
              "         [ 0.2 ,  1.55,  0.  ]], dtype=float32), array([[-0.55, -0.4 ,  0.  ],\n",
              "         [-0.15,  0.  ,  0.  ],\n",
              "         [-0.05, -0.05,  0.  ],\n",
              "         ...,\n",
              "         [ 0.5 ,  0.35,  0.  ],\n",
              "         [-0.15, -0.15,  0.  ],\n",
              "         [ 0.35, -0.1 ,  0.  ]], dtype=float32)],\n",
              " ['Fear would be a deterrent.',\n",
              "  'counselling patience until the',\n",
              "  'They would be loose-leave',\n",
              "  'Norway was quite adequately',\n",
              "  'In so intensive a contest',\n",
              "  'more adverse to anything but the',\n",
              "  'then led him by her subconscious',\n",
              "  'but perhaps she was giving',\n",
              "  'to form a continuous film.',\n",
              "  'important gap in our knowledge was',\n",
              "  'would be prepared to reach',\n",
              "  'the Commonwealth on trial. His ex-',\n",
              "  'it) drank four bottles of beer',\n",
              "  'was making fools of all of us.',\n",
              "  'would be wetter if he had more clothes',\n",
              "  'being a dictator. And yet he is',\n",
              "  'they burst into Czechoslovakia ,',\n",
              "  'repetition, the voice went on to',\n",
              "  'guide missiles onto bach-',\n",
              "  'in his pocket.\" Thanks, \"he said.\"'],\n",
              " [array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]), array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]])])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GSp8GvK47evo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}